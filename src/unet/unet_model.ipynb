{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3708b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "import cv2\n",
    "from pycocotools import mask as coco_mask \n",
    "%matplotlib inline\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03f80118",
   "metadata": {},
   "source": [
    "LOADING AND EXPLORING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe809805",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataSet/turtles-data/data/annotations.json', 'r', encoding='utf8') as file:\n",
    "    annotations = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26e7858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=30.23s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# initialise COCO API for annotations\n",
    "coco = COCO('dataSet/turtles-data/data/annotations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c25429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all image IDs\n",
    "img_ids = coco.getImgIds()\n",
    "cat_ids = coco.getCatIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842500c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_img_mask(img_ids):\n",
    "    images_and_masks = []\n",
    "\n",
    "    # Load batch of images\n",
    "    imgs = coco.loadImgs(img_ids)\n",
    "    anns_ids_batch = coco.getAnnIds(imgIds=img_ids, catIds=cat_ids, iscrowd=None)\n",
    "    anns_batch = coco.loadAnns(anns_ids_batch)\n",
    "\n",
    "    # Prepare a dictionary to hold masks for each image ID\n",
    "    mask_dict = {img['id']: np.zeros((img['height'], img['width']), dtype=np.uint8) for img in imgs}\n",
    "\n",
    "    # Generate the masks by adding each annotation to the appropriate image's mask\n",
    "    for ann in anns_batch:\n",
    "        img_id = ann['image_id']\n",
    "        mask_dict[img_id] = np.maximum(mask_dict[img_id], coco.annToMask(ann))\n",
    "\n",
    "    # Load images and pair with masks\n",
    "    for img in imgs:\n",
    "        file_name = f\"dataSet/turtles-data/data/{img['file_name']}\"\n",
    "        try:\n",
    "            image = np.array(Image.open(file_name))\n",
    "            mask = mask_dict[img['id']]\n",
    "            images_and_masks.append((image, mask))\n",
    "        except FileNotFoundError:\n",
    "            # Skip if image file is missing\n",
    "            continue\n",
    "\n",
    "    return images_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_splits_array(type, df, batch_size=10):\n",
    "    # Filter rows based on the specified type\n",
    "    filtered_df = df[df['split_open'] == type]\n",
    "    if type == \"train\":\n",
    "        filtered_df = filtered_df.sample(n=2500, random_state=42)\n",
    "    elif type == \"test\":\n",
    "        filtered_df = filtered_df.sample(n=1080, random_state=42)\n",
    "    elif type == \"valid\":\n",
    "        filtered_df = filtered_df.sample(n=527, random_state=42)\n",
    "    \n",
    "    img_ids = filtered_df['id'].tolist()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    img_len = math.floor(len(img_ids))\n",
    "\n",
    "    # Process in batches\n",
    "    for i in range(0, img_len, batch_size):\n",
    "        batch_img_ids = img_ids[i:i + batch_size]\n",
    "        batch_data = get_batch_img_mask(batch_img_ids)\n",
    "        \n",
    "        # Add only valid images and masks\n",
    "        for result in batch_data:\n",
    "            if result != -1:\n",
    "                data.append(result)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37de224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV file\n",
    "df = pd.read_csv(\"dataSet/turtles-data/data/metadata_splits.csv\")\n",
    "train_data = create_splits_array(\"train\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d4f0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_splits_array(\"test\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06eba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = create_splits_array(\"valid\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cf81b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data)\n",
    "len(train_data)\n",
    "len(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c16352336970d6637b423b0999f8e0286371151edd0114aa7d4081da9d79c418"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
